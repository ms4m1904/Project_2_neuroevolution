{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Neuroevolution Deliverable 2** ðŸ™‚"
      ],
      "metadata": {
        "id": "XplAvl5n-W54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Group I:\n",
        "\n",
        "Student Name       | Student Email\n",
        "-------------------|------------------\n",
        "Filipe Dias        | r20181050@novaims.unl.pt\n",
        "InÃªs Santos        | r20191184@novaims.unl.pt\n",
        "Manuel Marreiros   | r20191223@novaims.unl.pt"
      ],
      "metadata": {
        "id": "tCfpIJnRpLjy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2oytyjtzh-5w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "import random\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as nnf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets , transforms\n",
        "from dataclasses import dataclass\n",
        "import torchvision.transforms as T \n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dY46gT9FhtTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27e2813-f6ad-49da-dec5-e4c003ecb514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9912422/9912422 [00:00<00:00, 148272335.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28881/28881 [00:00<00:00, 26118088.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1648877/1648877 [00:00<00:00, 36082848.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [00:00<00:00, 5840137.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "train_dataset = datasets.MNIST('./data', \n",
        "                               train=True, \n",
        "                               download=True, \n",
        "                               transform=transforms.ToTensor())\n",
        "\n",
        "validation_dataset = datasets.MNIST('./data', \n",
        "                                    train=False, \n",
        "                                    transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                            batch_size=batch_size, \n",
        "                            shuffle=True)\n",
        "\n",
        "validation_loader = DataLoader(dataset=validation_dataset, \n",
        "                                batch_size=batch_size, \n",
        "                                shuffle=False)\n",
        "\n",
        "input_size = 28*28\n",
        "output_size =  10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Grammar"
      ],
      "metadata": {
        "id": "I5fSazEg-WHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dictionary contains the different layers that can be used by the models and the respective parameters with values that will be drawn at random."
      ],
      "metadata": {
        "id": "u8wm9xl2dM1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_params = {\n",
        "    'Linear': {\n",
        "        'in_features': [64, 128, 256, 512],\n",
        "        'out_features': [512, 256, 128, 64, 32, 16],\n",
        "        'bias': [True, False]\n",
        "    },\n",
        "    'BatchNorm1d': {\n",
        "        'eps': [1e-5, 1e-4, 1e-3],\n",
        "        'momentum': [0.1, 0.9, 0.99]\n",
        "    },\n",
        "    'LayerNorm': {\n",
        "        'eps': [1e-5, 1e-4, 1e-3]\n",
        "    },\n",
        "    'Dropout': {\n",
        "        'p': [0.1, 0.5, 0.7]\n",
        "    },\n",
        "    'AlphaDropout': {\n",
        "        'p': [0.1, 0.5, 0.7]\n",
        "    },\n",
        "    'Activation': ['Sigmoid', 'ReLU', 'PReLU', 'ELU', 'SELU', 'GELU', 'CELU', 'SiLU']\n",
        "}\n"
      ],
      "metadata": {
        "id": "WUAZcOyH70eH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function will generate a random network with at least 2 layers and maximum 50 layers.\n",
        "\n",
        "The only predefined layers are the first and last ones, which will be linear layers. All the other layers will be selected randomly from the dictionary above.\n",
        "\n",
        " The softmax layer at the end is only defined at the training stage to convert the raw output of the model into probabilities at that point."
      ],
      "metadata": {
        "id": "QYgCMcaodbg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_network(input_size, output_size, min_layers, max_layers):\n",
        "    # Randomly choose the number of layers (excluding the first and last layers)\n",
        "    num_layers = random.randint(min_layers, max_layers - 2)\n",
        "\n",
        "    # Randomly select layers and their parameters\n",
        "    layer_list = []\n",
        "    \n",
        "    # Add the first linear layer\n",
        "    first_layer_string = f'Linear|{input_size},512,True'\n",
        "    previous_output_features = 512\n",
        "    layer_list.append(first_layer_string)\n",
        "\n",
        "    # Add the intermediate layers\n",
        "    for _ in range(num_layers):\n",
        "        layer_type = random.choice(list(layer_params.keys()))\n",
        "\n",
        "        if layer_type == 'Activation':\n",
        "            activation_fn = random.choice(layer_params[layer_type])\n",
        "            layer_string = f'Act|{activation_fn}'\n",
        "        else:\n",
        "            layer_params_dict = {}\n",
        "            for param, values in layer_params[layer_type].items():\n",
        "                layer_params_dict[param] = random.choice(values)\n",
        "\n",
        "            if layer_type == 'Linear':\n",
        "                layer_params_dict['in_features'] = previous_output_features\n",
        "                previous_output_features = layer_params_dict['out_features']            \n",
        "                param_string = ','.join([str(value) for value in layer_params_dict.values()])\n",
        "                layer_string = f'{layer_type}|{param_string}'\n",
        "\n",
        "            elif layer_type == 'BatchNorm1d':\n",
        "                param_string = ','.join([str(value) for value in layer_params_dict.values()])\n",
        "                layer_string = f'{layer_type}|{previous_output_features},{param_string}'\n",
        "\n",
        "            elif layer_type == 'LayerNorm':\n",
        "                param_string = ','.join([str(value) for value in layer_params_dict.values()])\n",
        "                layer_string = f'{layer_type}|{previous_output_features},{param_string}'\n",
        "            \n",
        "            else:\n",
        "                param_string = ','.join([str(value) for value in layer_params_dict.values()])\n",
        "                layer_string = f'{layer_type}|{param_string}'\n",
        "\n",
        "        layer_list.append(layer_string)\n",
        "\n",
        "    # Add the last linear layer\n",
        "    last_layer_string = f'Linear|{previous_output_features},{output_size},True'\n",
        "    layer_list.append(last_layer_string)\n",
        "\n",
        "    return layer_list\n",
        "\n",
        "# Defining the number of layers\n",
        "min_layers = 2\n",
        "max_layers = 50"
      ],
      "metadata": {
        "id": "MyZLL3ko75g7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JSYi4aNwiTe8"
      },
      "outputs": [],
      "source": [
        "# Define network class to parse instructions and build PyTorch network structure (phenotype)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, layer_list):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for layer_str in layer_list:\n",
        "            layer = self.parse_layer_string(layer_str)\n",
        "            self.layers.append(layer)\n",
        "\n",
        "        # to flatten the images into 1d arays\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=self.flat(x)\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)    \n",
        "        return x\n",
        "\n",
        "    def parse_layer_string(self, layer_str):\n",
        "        if layer_str.startswith('Linear'):\n",
        "            features = layer_str.split('|')[-1].split(',')\n",
        "            in_features = int(features[0])\n",
        "            out_features = int(features[1])\n",
        "            bias = features[-1]\n",
        "            return nn.Linear(in_features, out_features, bias)\n",
        "        elif layer_str.startswith('BatchNorm1d'):\n",
        "            features = layer_str.split('|')[-1].split(',')\n",
        "            num_features = int(features[0])\n",
        "            eps = float(features[1])\n",
        "            momentum = float(features[2])\n",
        "            return nn.BatchNorm1d(num_features, eps, momentum)\n",
        "        elif layer_str.startswith('LayerNorm'):\n",
        "            features = layer_str.split('|')[-1].split(',')\n",
        "            shape = int(features[0])\n",
        "            eps = float(features[1])\n",
        "            return nn.LayerNorm(normalized_shape=[16, shape], eps=eps) #16 is the batch size, shape is the current input shape\n",
        "        elif layer_str.startswith('Dropout'):\n",
        "            p = float(layer_str.split('|')[-1])\n",
        "            return nn.Dropout(p=p)\n",
        "        elif layer_str.startswith('AlphaDropout'):\n",
        "            p = float(layer_str.split('|')[-1])\n",
        "            return nn.AlphaDropout(p=p)\n",
        "        elif layer_str.startswith('Act'):\n",
        "            act = layer_str.split('|')[-1]\n",
        "            layer_class = getattr(nn,act)\n",
        "            return layer_class()\n",
        "        else:\n",
        "            raise ValueError('Invalid layer string: {}'.format(layer_str))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next dictionary contains the different optimizers and the respective parameters with values that will be drawn at random."
      ],
      "metadata": {
        "id": "HFiDbOQAeYC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer_params = {\n",
        "    'Adam': {\n",
        "        'lr': [0.001, 0.01, 0.1],\n",
        "        'betas': [(0.9, 0.999), (0.85, 0.95), (0.8, 0.9)]\n",
        "    },\n",
        "    'AdamW': {\n",
        "        'lr': [0.001, 0.01, 0.1],\n",
        "        'betas': [(0.9, 0.999), (0.85, 0.95), (0.8, 0.9)],\n",
        "        'weight_decay': [0.0, 0.001, 0.01]\n",
        "    },\n",
        "    'Adadelta': {\n",
        "        'lr': [0.1, 1.0, 10.0],\n",
        "        'rho': [0.9, 0.95, 0.99]\n",
        "    },\n",
        "    'NAdam': {\n",
        "        'lr': [0.001, 0.01, 0.1],\n",
        "        'betas': [(0.9, 0.999), (0.85, 0.95), (0.8, 0.9)],\n",
        "        'momentum_decay': [0.9, 0.95, 0.99]\n",
        "    },\n",
        "    'SGD': {\n",
        "        'lr': [0.01, 0.1, 1.0],\n",
        "        'momentum': [0.9, 0.95, 0.99],\n",
        "        'nesterov': [True, False]\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "id": "Cmxlb3LRpQdZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "__QoaRcewlDO"
      },
      "outputs": [],
      "source": [
        "# Define function to parse optimizer instructions and build PyTorch optimizer\n",
        "def build_optimizer(optimizer_str, params, model):\n",
        "    # Parse the optimizer string and create a PyTorch optimizer\n",
        "    if optimizer_str == 'SGD':\n",
        "        lr = params['lr']\n",
        "        momentum = params['momentum']\n",
        "        nesterov = params['nesterov']\n",
        "        return torch.optim.SGD(params=model.parameters(), lr=lr, momentum=momentum, nesterov=nesterov)\n",
        "    elif optimizer_str == 'Adam':\n",
        "        lr = params['lr']\n",
        "        betas = params['betas']\n",
        "        return torch.optim.Adam(params=model.parameters(), lr=lr, betas=betas)\n",
        "    elif optimizer_str == 'AdamW':\n",
        "        lr = params['lr']\n",
        "        betas = params['betas']\n",
        "        weight_decay = params['weight_decay']\n",
        "        return torch.optim.AdamW(params=model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
        "    elif optimizer_str == 'NAdam':\n",
        "        lr = params['lr']\n",
        "        betas = params['betas']\n",
        "        momentum_decay = params['momentum_decay']\n",
        "        return torch.optim.NAdam(params=model.parameters(), lr=lr, betas=betas, momentum_decay=momentum_decay)\n",
        "    elif optimizer_str == 'Adadelta':\n",
        "        lr = params['lr']\n",
        "        rho = params['rho']\n",
        "        return torch.optim.Adadelta(params=model.parameters(), lr=lr, rho=rho)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 1"
      ],
      "metadata": {
        "id": "zyiYy-ybylKx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_list = generate_random_network(input_size, output_size, min_layers, max_layers)\n",
        "\n",
        "# Print the randomly generated network\n",
        "print(\"Layer List:\", layer_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iou6RommeuqJ",
        "outputId": "95f22de4-609b-4d01-c7ac-40aa371e7759"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer List: ['Linear|784,512,True', 'AlphaDropout|0.7', 'Linear|512,64,False', 'LayerNorm|64,0.001', 'Dropout|0.1', 'Dropout|0.7', 'AlphaDropout|0.1', 'BatchNorm1d|64,0.001,0.1', 'BatchNorm1d|64,1e-05,0.1', 'Dropout|0.7', 'AlphaDropout|0.7', 'BatchNorm1d|64,0.001,0.99', 'Linear|64,512,False', 'AlphaDropout|0.7', 'Dropout|0.1', 'AlphaDropout|0.1', 'AlphaDropout|0.7', 'Act|GELU', 'BatchNorm1d|512,1e-05,0.1', 'AlphaDropout|0.1', 'Linear|512,128,True', 'Linear|128,256,False', 'Linear|256,32,False', 'Dropout|0.1', 'Linear|32,32,True', 'Linear|32,10,True']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LcW-UqRvrtOA"
      },
      "outputs": [],
      "source": [
        "model1 = Net(layer_list).to(device)\n",
        "\n",
        "# Define the loss function, we will use the standard Binary Crossentropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyxUBCXWdA3t",
        "outputId": "5225f906-93d7-4ec3-e73d-c78b222bafd2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): AlphaDropout(p=0.7, inplace=False)\n",
              "    (2): Linear(in_features=512, out_features=64, bias=True)\n",
              "    (3): LayerNorm((16, 64), eps=0.001, elementwise_affine=True)\n",
              "    (4): Dropout(p=0.1, inplace=False)\n",
              "    (5): Dropout(p=0.7, inplace=False)\n",
              "    (6): AlphaDropout(p=0.1, inplace=False)\n",
              "    (7): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): Dropout(p=0.7, inplace=False)\n",
              "    (10): AlphaDropout(p=0.7, inplace=False)\n",
              "    (11): BatchNorm1d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (12): Linear(in_features=64, out_features=512, bias=True)\n",
              "    (13): AlphaDropout(p=0.7, inplace=False)\n",
              "    (14): Dropout(p=0.1, inplace=False)\n",
              "    (15): AlphaDropout(p=0.1, inplace=False)\n",
              "    (16): AlphaDropout(p=0.7, inplace=False)\n",
              "    (17): GELU(approximate='none')\n",
              "    (18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): AlphaDropout(p=0.1, inplace=False)\n",
              "    (20): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (21): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (22): Linear(in_features=256, out_features=32, bias=True)\n",
              "    (23): Dropout(p=0.1, inplace=False)\n",
              "    (24): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (25): Linear(in_features=32, out_features=10, bias=True)\n",
              "  )\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select an optimizer\n",
        "optimizer_str = random.choice(list(optimizer_params.keys()))\n",
        "\n",
        "# Randomly select parameters for the chosen optimizer\n",
        "params = {}\n",
        "for param, values in optimizer_params[optimizer_str].items():\n",
        "    params[param] = random.choice(values)\n",
        "\n",
        "# Print the randomly generated optimizer and its parameters\n",
        "print(\"Optimizer:\", optimizer_str)\n",
        "print(\"Parameters:\", params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANxSdISUpVD4",
        "outputId": "2fd851e4-5498-4d48-a6e1-13cb9a15e5a7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: NAdam\n",
            "Parameters: {'lr': 0.001, 'betas': (0.9, 0.999), 'momentum_decay': 0.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xyKqA_Y5yi7S"
      },
      "outputs": [],
      "source": [
        "optimizer = build_optimizer(optimizer_str, params, model1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model):\n",
        "    num_epochs = 10\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        accuracy_hist_train = 0\n",
        "        loss_hist_train = 0\n",
        "\n",
        "        model.train()  # Set the model to training mode\n",
        "\n",
        "        for x_batch, y_batch in train_loader:\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            pred = model(x_batch)\n",
        "            pred_probs = nnf.softmax(pred, dim=1)\n",
        "            loss = loss_fn(pred, y_batch)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Compute training accuracy\n",
        "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
        "            accuracy_hist_train += is_correct.sum().item()\n",
        "            loss_hist_train += loss.item()\n",
        "\n",
        "        accuracy_hist_train /= len(train_loader.dataset)\n",
        "        loss_hist_train /= len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        accuracy_hist_val = 0\n",
        "        loss_hist_val = 0\n",
        "\n",
        "        model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for x_val, y_val in validation_loader:\n",
        "                x_val = x_val.to(device)\n",
        "                y_val = y_val.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                val_pred = model(x_val)\n",
        "                val_pred_probs = nnf.softmax(val_pred, dim=1)\n",
        "                val_loss = loss_fn(val_pred, y_val)\n",
        "\n",
        "                # Compute validation accuracy\n",
        "                val_is_correct = (torch.argmax(val_pred, dim=1) == y_val).float()\n",
        "                accuracy_hist_val += val_is_correct.sum().item()\n",
        "                loss_hist_val += val_loss.item()\n",
        "\n",
        "        accuracy_hist_val /= len(validation_loader.dataset)\n",
        "        loss_hist_val /= len(validation_loader)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        print(f\"Training Loss: {loss_hist_train:.4f}  Training Accuracy: {accuracy_hist_train:.4f}\")\n",
        "        print(f\"Validation Loss: {loss_hist_val:.4f}  Validation Accuracy: {accuracy_hist_val:.4f}\")\n",
        "        print(\"------------------------\")\n"
      ],
      "metadata": {
        "id": "wYidylYefe55"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9enFR2ffh_A",
        "outputId": "9d773f65-6f29-4f4a-eb09-748f92e3d755"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 2.3072  Training Accuracy: 0.1039\n",
            "Validation Loss: 2.3005  Validation Accuracy: 0.1135\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 2.3047  Training Accuracy: 0.1087\n",
            "Validation Loss: 2.3008  Validation Accuracy: 0.1019\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 2.3035  Training Accuracy: 0.1081\n",
            "Validation Loss: 2.3037  Validation Accuracy: 0.1135\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 2.3027  Training Accuracy: 0.1105\n",
            "Validation Loss: 2.2996  Validation Accuracy: 0.1135\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 2.3026  Training Accuracy: 0.1106\n",
            "Validation Loss: 2.3016  Validation Accuracy: 0.1028\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 2.3028  Training Accuracy: 0.1102\n",
            "Validation Loss: 2.3003  Validation Accuracy: 0.1135\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 2.3028  Training Accuracy: 0.1105\n",
            "Validation Loss: 2.3008  Validation Accuracy: 0.1541\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 2.3029  Training Accuracy: 0.1101\n",
            "Validation Loss: 2.2948  Validation Accuracy: 0.1177\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 2.3029  Training Accuracy: 0.1100\n",
            "Validation Loss: 2.3163  Validation Accuracy: 0.1031\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 2.3030  Training Accuracy: 0.1093\n",
            "Validation Loss: 2.2985  Validation Accuracy: 0.1138\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 2"
      ],
      "metadata": {
        "id": "PrhO39t2yo6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_list = generate_random_network(input_size, output_size, min_layers, max_layers)\n",
        "\n",
        "# Print the randomly generated network\n",
        "print(\"Layer List:\", layer_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb5bD8BNhEdy",
        "outputId": "63cf8a78-a233-4137-af80-d65c4c149621"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer List: ['Linear|784,512,True', 'Act|ELU', 'AlphaDropout|0.1', 'BatchNorm1d|512,1e-05,0.99', 'AlphaDropout|0.1', 'Act|ReLU', 'Act|CELU', 'BatchNorm1d|512,0.001,0.9', 'BatchNorm1d|512,0.0001,0.9', 'Dropout|0.5', 'AlphaDropout|0.7', 'Dropout|0.7', 'LayerNorm|512,0.0001', 'LayerNorm|512,0.0001', 'BatchNorm1d|512,0.0001,0.9', 'BatchNorm1d|512,0.001,0.1', 'Linear|512,512,True', 'LayerNorm|512,1e-05', 'Dropout|0.5', 'Dropout|0.1', 'Linear|512,128,True', 'Dropout|0.7', 'Act|ELU', 'BatchNorm1d|128,0.0001,0.1', 'AlphaDropout|0.5', 'Act|CELU', 'LayerNorm|128,0.0001', 'Act|ELU', 'BatchNorm1d|128,1e-05,0.9', 'LayerNorm|128,0.001', 'Dropout|0.5', 'Linear|128,256,False', 'Dropout|0.7', 'Dropout|0.1', 'Linear|256,10,True']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Net(layer_list).to(device)\n",
        "\n",
        "# Define the loss function, we will use the standard Binary Crossentropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "_C53eDfGhI77"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93nA83LrhKzZ",
        "outputId": "bce620e2-2ffb-413e-da01-47f6288988eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ELU(alpha=1.0)\n",
              "    (2): AlphaDropout(p=0.1, inplace=False)\n",
              "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (4): AlphaDropout(p=0.1, inplace=False)\n",
              "    (5): ReLU()\n",
              "    (6): CELU(alpha=1.0)\n",
              "    (7): BatchNorm1d(512, eps=0.001, momentum=0.9, affine=True, track_running_stats=True)\n",
              "    (8): BatchNorm1d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
              "    (9): Dropout(p=0.5, inplace=False)\n",
              "    (10): AlphaDropout(p=0.7, inplace=False)\n",
              "    (11): Dropout(p=0.7, inplace=False)\n",
              "    (12-13): 2 x LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
              "    (14): BatchNorm1d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
              "    (15): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (17): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
              "    (18): Dropout(p=0.5, inplace=False)\n",
              "    (19): Dropout(p=0.1, inplace=False)\n",
              "    (20): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (21): Dropout(p=0.7, inplace=False)\n",
              "    (22): ELU(alpha=1.0)\n",
              "    (23): BatchNorm1d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): AlphaDropout(p=0.5, inplace=False)\n",
              "    (25): CELU(alpha=1.0)\n",
              "    (26): LayerNorm((16, 128), eps=0.0001, elementwise_affine=True)\n",
              "    (27): ELU(alpha=1.0)\n",
              "    (28): BatchNorm1d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "    (29): LayerNorm((16, 128), eps=0.001, elementwise_affine=True)\n",
              "    (30): Dropout(p=0.5, inplace=False)\n",
              "    (31): Linear(in_features=128, out_features=256, bias=True)\n",
              "    (32): Dropout(p=0.7, inplace=False)\n",
              "    (33): Dropout(p=0.1, inplace=False)\n",
              "    (34): Linear(in_features=256, out_features=10, bias=True)\n",
              "  )\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select an optimizer\n",
        "optimizer_str = random.choice(list(optimizer_params.keys()))\n",
        "\n",
        "# Randomly select parameters for the chosen optimizer\n",
        "params = {}\n",
        "for param, values in optimizer_params[optimizer_str].items():\n",
        "    params[param] = random.choice(values)\n",
        "\n",
        "# Print the randomly generated optimizer and its parameters\n",
        "print(\"Optimizer:\", optimizer_str)\n",
        "print(\"Parameters:\", params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo21FpVThPMY",
        "outputId": "3c7fdaac-2857-4766-f1c8-159f329da4c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: Adadelta\n",
            "Parameters: {'lr': 10.0, 'rho': 0.9}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = build_optimizer(optimizer_str, params, model2)"
      ],
      "metadata": {
        "id": "7IstrI9OhSMx"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model2)"
      ],
      "metadata": {
        "id": "9xBDrhHKhYbH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48e92d4-bd44-47a0-eac6-5a2173416a67"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 4.7165  Training Accuracy: 0.1010\n",
            "Validation Loss: 2.7371  Validation Accuracy: 0.0997\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 3.4654  Training Accuracy: 0.1006\n",
            "Validation Loss: 2.6682  Validation Accuracy: 0.1022\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 3.4435  Training Accuracy: 0.1023\n",
            "Validation Loss: 2.8221  Validation Accuracy: 0.0965\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 3.4484  Training Accuracy: 0.0997\n",
            "Validation Loss: 2.6729  Validation Accuracy: 0.1012\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 3.4465  Training Accuracy: 0.1004\n",
            "Validation Loss: 2.6483  Validation Accuracy: 0.1021\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 3.4383  Training Accuracy: 0.1003\n",
            "Validation Loss: 2.7669  Validation Accuracy: 0.1038\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 3.4360  Training Accuracy: 0.1016\n",
            "Validation Loss: 2.7467  Validation Accuracy: 0.1040\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 3.4305  Training Accuracy: 0.0998\n",
            "Validation Loss: 2.8899  Validation Accuracy: 0.1031\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 3.4275  Training Accuracy: 0.1010\n",
            "Validation Loss: 2.6995  Validation Accuracy: 0.1024\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 3.4344  Training Accuracy: 0.1029\n",
            "Validation Loss: 2.6325  Validation Accuracy: 0.1033\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 3"
      ],
      "metadata": {
        "id": "YjD2ww8jyrg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_list = generate_random_network(input_size, output_size, min_layers, max_layers)\n",
        "\n",
        "# Print the randomly generated network\n",
        "print(\"Layer List:\", layer_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc14f028-5ff8-4132-9921-5731c8fa801a",
        "id": "xTw9t66qjlou"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer List: ['Linear|784,512,True', 'AlphaDropout|0.1', 'BatchNorm1d|512,0.001,0.9', 'BatchNorm1d|512,0.001,0.1', 'Act|Sigmoid', 'BatchNorm1d|512,0.001,0.99', 'Act|SiLU', 'LayerNorm|512,0.0001', 'Act|SELU', 'AlphaDropout|0.7', 'LayerNorm|512,0.001', 'AlphaDropout|0.1', 'LayerNorm|512,0.0001', 'Act|CELU', 'Linear|512,64,False', 'Dropout|0.7', 'AlphaDropout|0.5', 'AlphaDropout|0.7', 'Act|Sigmoid', 'AlphaDropout|0.7', 'LayerNorm|64,0.0001', 'Dropout|0.5', 'Linear|64,256,True', 'Linear|256,128,False', 'BatchNorm1d|128,1e-05,0.9', 'Act|ELU', 'BatchNorm1d|128,0.0001,0.1', 'AlphaDropout|0.7', 'LayerNorm|128,1e-05', 'Act|SiLU', 'Act|SELU', 'LayerNorm|128,0.001', 'BatchNorm1d|128,0.001,0.1', 'Linear|128,10,True']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = Net(layer_list).to(device)\n",
        "\n",
        "# Define the loss function, we will use the standard Binary Crossentropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ZsxizNkOjlpT"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd8b3a1-b37a-49e0-972f-0b0ed8c8d7f1",
        "id": "66VSoyyGjlpU"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): AlphaDropout(p=0.1, inplace=False)\n",
              "    (2): BatchNorm1d(512, eps=0.001, momentum=0.9, affine=True, track_running_stats=True)\n",
              "    (3): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Sigmoid()\n",
              "    (5): BatchNorm1d(512, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
              "    (6): SiLU()\n",
              "    (7): LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
              "    (8): SELU()\n",
              "    (9): AlphaDropout(p=0.7, inplace=False)\n",
              "    (10): LayerNorm((16, 512), eps=0.001, elementwise_affine=True)\n",
              "    (11): AlphaDropout(p=0.1, inplace=False)\n",
              "    (12): LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
              "    (13): CELU(alpha=1.0)\n",
              "    (14): Linear(in_features=512, out_features=64, bias=True)\n",
              "    (15): Dropout(p=0.7, inplace=False)\n",
              "    (16): AlphaDropout(p=0.5, inplace=False)\n",
              "    (17): AlphaDropout(p=0.7, inplace=False)\n",
              "    (18): Sigmoid()\n",
              "    (19): AlphaDropout(p=0.7, inplace=False)\n",
              "    (20): LayerNorm((16, 64), eps=0.0001, elementwise_affine=True)\n",
              "    (21): Dropout(p=0.5, inplace=False)\n",
              "    (22): Linear(in_features=64, out_features=256, bias=True)\n",
              "    (23): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (24): BatchNorm1d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
              "    (25): ELU(alpha=1.0)\n",
              "    (26): BatchNorm1d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): AlphaDropout(p=0.7, inplace=False)\n",
              "    (28): LayerNorm((16, 128), eps=1e-05, elementwise_affine=True)\n",
              "    (29): SiLU()\n",
              "    (30): SELU()\n",
              "    (31): LayerNorm((16, 128), eps=0.001, elementwise_affine=True)\n",
              "    (32): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (33): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select an optimizer\n",
        "optimizer_str = random.choice(list(optimizer_params.keys()))\n",
        "\n",
        "# Randomly select parameters for the chosen optimizer\n",
        "params = {}\n",
        "for param, values in optimizer_params[optimizer_str].items():\n",
        "    params[param] = random.choice(values)\n",
        "\n",
        "# Print the randomly generated optimizer and its parameters\n",
        "print(\"Optimizer:\", optimizer_str)\n",
        "print(\"Parameters:\", params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3abd0f4-cb75-43f2-ab74-fbf37be07825",
        "id": "dn7BOtrujlpV"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: Adam\n",
            "Parameters: {'lr': 0.001, 'betas': (0.85, 0.95)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = build_optimizer(optimizer_str, params, model3)"
      ],
      "metadata": {
        "id": "Flqmt17RjlpW"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model3)"
      ],
      "metadata": {
        "id": "73jLscuEjlpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e021660-e65d-4ff0-ddcb-847a729bb5f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 2.3344  Training Accuracy: 0.1021\n",
            "Validation Loss: 2.2422  Validation Accuracy: 0.1661\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 2.3145  Training Accuracy: 0.1026\n",
            "Validation Loss: 2.2134  Validation Accuracy: 0.2435\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 2.3107  Training Accuracy: 0.1047\n",
            "Validation Loss: 2.2704  Validation Accuracy: 0.1824\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 2.3068  Training Accuracy: 0.1037\n",
            "Validation Loss: 2.2456  Validation Accuracy: 0.2592\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 2.3046  Training Accuracy: 0.1060\n",
            "Validation Loss: 2.2757  Validation Accuracy: 0.2165\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 2.3032  Training Accuracy: 0.1080\n",
            "Validation Loss: 2.2772  Validation Accuracy: 0.2506\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 2.3021  Training Accuracy: 0.1084\n",
            "Validation Loss: 2.2923  Validation Accuracy: 0.1288\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 2.3026  Training Accuracy: 0.1103\n",
            "Validation Loss: 2.2992  Validation Accuracy: 0.1135\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 2.3023  Training Accuracy: 0.1091\n",
            "Validation Loss: 2.2980  Validation Accuracy: 0.1255\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 2.3023  Training Accuracy: 0.1100\n",
            "Validation Loss: 2.2923  Validation Accuracy: 0.1235\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 4"
      ],
      "metadata": {
        "id": "w8fsx0gHytLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_list = generate_random_network(input_size, output_size, min_layers, max_layers)\n",
        "\n",
        "# Print the randomly generated network\n",
        "print(\"Layer List:\", layer_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec37319-91d6-4881-cf7f-b1d1ecb87717",
        "id": "2t_1g1fnjp3Y"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer List: ['Linear|784,512,True', 'Act|ELU', 'Act|SiLU', 'LayerNorm|512,1e-05', 'LayerNorm|512,0.001', 'Linear|512,512,True', 'LayerNorm|512,0.0001', 'Linear|512,10,True']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = Net(layer_list).to(device)\n",
        "\n",
        "# Define the loss function, we will use the standard Binary Crossentropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "fIQ5AhOAjp3a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b9d7d7b-140b-4a39-d3e3-5e0218df0d34",
        "id": "6BSvpZCIjp3b"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): ELU(alpha=1.0)\n",
              "    (2): SiLU()\n",
              "    (3): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
              "    (4): LayerNorm((16, 512), eps=0.001, elementwise_affine=True)\n",
              "    (5): Linear(in_features=512, out_features=512, bias=True)\n",
              "    (6): LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
              "    (7): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select an optimizer\n",
        "optimizer_str = random.choice(list(optimizer_params.keys()))\n",
        "\n",
        "# Randomly select parameters for the chosen optimizer\n",
        "params = {}\n",
        "for param, values in optimizer_params[optimizer_str].items():\n",
        "    params[param] = random.choice(values)\n",
        "\n",
        "# Print the randomly generated optimizer and its parameters\n",
        "print(\"Optimizer:\", optimizer_str)\n",
        "print(\"Parameters:\", params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc638fb6-a62d-4f1e-c9db-a3d961fb35a0",
        "id": "uSRXY47Kjp3c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: Adam\n",
            "Parameters: {'lr': 0.001, 'betas': (0.8, 0.9)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = build_optimizer(optimizer_str, params, model4)"
      ],
      "metadata": {
        "id": "0QmPDJm1jp3e"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model4)"
      ],
      "metadata": {
        "id": "E9hmZUazjp3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a45766d4-416d-49ca-f2d1-0d8bc06b89c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 0.2643  Training Accuracy: 0.9220\n",
            "Validation Loss: 0.1431  Validation Accuracy: 0.9604\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 0.1269  Training Accuracy: 0.9633\n",
            "Validation Loss: 0.1164  Validation Accuracy: 0.9673\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 0.0970  Training Accuracy: 0.9719\n",
            "Validation Loss: 0.1077  Validation Accuracy: 0.9713\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 0.0822  Training Accuracy: 0.9766\n",
            "Validation Loss: 0.0997  Validation Accuracy: 0.9716\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 0.0711  Training Accuracy: 0.9798\n",
            "Validation Loss: 0.0944  Validation Accuracy: 0.9731\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 0.0619  Training Accuracy: 0.9825\n",
            "Validation Loss: 0.1020  Validation Accuracy: 0.9725\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 0.0576  Training Accuracy: 0.9840\n",
            "Validation Loss: 0.0916  Validation Accuracy: 0.9765\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 0.0497  Training Accuracy: 0.9854\n",
            "Validation Loss: 0.0975  Validation Accuracy: 0.9779\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 0.0468  Training Accuracy: 0.9868\n",
            "Validation Loss: 0.0869  Validation Accuracy: 0.9783\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 0.0424  Training Accuracy: 0.9877\n",
            "Validation Loss: 0.0972  Validation Accuracy: 0.9771\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 5"
      ],
      "metadata": {
        "id": "17PIK_5ryx32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_list = generate_random_network(input_size, output_size, min_layers, max_layers)\n",
        "\n",
        "# Print the randomly generated network\n",
        "print(\"Layer List:\", layer_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c902bb-92b5-4e74-8cdd-551ed7486206",
        "id": "YdA612leju7I"
      },
      "execution_count": 33,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer List: ['Linear|784,512,True', 'Dropout|0.5', 'AlphaDropout|0.5', 'Act|GELU', 'LayerNorm|512,1e-05', 'Dropout|0.1', 'Act|CELU', 'Act|SELU', 'AlphaDropout|0.1', 'LayerNorm|512,0.001', 'AlphaDropout|0.5', 'LayerNorm|512,0.0001', 'LayerNorm|512,1e-05', 'AlphaDropout|0.7', 'BatchNorm1d|512,1e-05,0.1', 'LayerNorm|512,0.0001', 'LayerNorm|512,0.0001', 'Linear|512,10,True']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = Net(layer_list).to(device)\n",
        "\n",
        "# Define the loss function, we will use the standard Binary Crossentropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "kVlyy0cpju7K"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc89241-e074-47e8-b5c1-ddf98795413a",
        "id": "62z60sxRju7L"
      },
      "execution_count": 35,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Net(\n",
              "  (layers): ModuleList(\n",
              "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "    (2): AlphaDropout(p=0.5, inplace=False)\n",
              "    (3): GELU(approximate='none')\n",
              "    (4): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
              "    (5): Dropout(p=0.1, inplace=False)\n",
              "    (6): CELU(alpha=1.0)\n",
              "    (7): SELU()\n",
              "    (8): AlphaDropout(p=0.1, inplace=False)\n",
              "    (9): LayerNorm((16, 512), eps=0.001, elementwise_affine=True)\n",
              "    (10): AlphaDropout(p=0.5, inplace=False)\n",
              "    (11): LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
              "    (12): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
              "    (13): AlphaDropout(p=0.7, inplace=False)\n",
              "    (14): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (15-16): 2 x LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
              "    (17): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
              ")"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly select an optimizer\n",
        "optimizer_str = random.choice(list(optimizer_params.keys()))\n",
        "\n",
        "# Randomly select parameters for the chosen optimizer\n",
        "params = {}\n",
        "for param, values in optimizer_params[optimizer_str].items():\n",
        "    params[param] = random.choice(values)\n",
        "\n",
        "# Print the randomly generated optimizer and its parameters\n",
        "print(\"Optimizer:\", optimizer_str)\n",
        "print(\"Parameters:\", params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba6f578b-b8c7-4180-84dd-ec0f461ec619",
        "id": "u8FeGOxPju7M"
      },
      "execution_count": 36,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimizer: AdamW\n",
            "Parameters: {'lr': 0.001, 'betas': (0.85, 0.95), 'weight_decay': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = build_optimizer(optimizer_str, params, model5)"
      ],
      "metadata": {
        "id": "8tCE7DWSju7N"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model5)"
      ],
      "metadata": {
        "id": "0va6PWTWju7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e05d898-2d7f-421c-ed00-e82764011fe8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 2.3583  Training Accuracy: 0.1324\n",
            "Validation Loss: 0.6179  Validation Accuracy: 0.8220\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 2.3542  Training Accuracy: 0.1301\n",
            "Validation Loss: 0.8411  Validation Accuracy: 0.7654\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 2.3572  Training Accuracy: 0.1264\n",
            "Validation Loss: 1.1082  Validation Accuracy: 0.7089\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 2.3528  Training Accuracy: 0.1235\n",
            "Validation Loss: 1.3362  Validation Accuracy: 0.6020\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 2.3480  Training Accuracy: 0.1264\n",
            "Validation Loss: 1.4301  Validation Accuracy: 0.4936\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 2.3391  Training Accuracy: 0.1259\n",
            "Validation Loss: 1.5244  Validation Accuracy: 0.4723\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 2.3327  Training Accuracy: 0.1283\n",
            "Validation Loss: 1.4946  Validation Accuracy: 0.4743\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 2.3174  Training Accuracy: 0.1323\n",
            "Validation Loss: 1.4359  Validation Accuracy: 0.5008\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 2.2941  Training Accuracy: 0.1453\n",
            "Validation Loss: 1.3952  Validation Accuracy: 0.5531\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 2.2599  Training Accuracy: 0.1596\n",
            "Validation Loss: 1.4031  Validation Accuracy: 0.5185\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crossover between networks 1 and 2"
      ],
      "metadata": {
        "id": "kITDDHFxfwJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crossover_networks(network1, network2):\n",
        "    # Copy the networks to avoid modifying the original networks\n",
        "    network1_copy = copy.deepcopy(network1)\n",
        "    network2_copy = copy.deepcopy(network2)\n",
        "\n",
        "    # Determine the cutoff points based on the smaller network's size\n",
        "    min_num_layers = min(len(network1_copy.layers), len(network2_copy.layers))\n",
        "\n",
        "    # Generate two unique cutoff points within the valid range\n",
        "    valid_range = range(1, min_num_layers - 1)\n",
        "    cutoff_points = random.sample(valid_range, 2)\n",
        "    cutoff_points.sort()\n",
        "    print(\"The cutoff points for the crossover are\", cutoff_points)\n",
        "\n",
        "    # Swap the blocks of layers between the networks\n",
        "    for i in range(cutoff_points[0], cutoff_points[1] + 1):\n",
        "        network1_copy.layers[i], network2_copy.layers[i] = network2_copy.layers[i], network1_copy.layers[i]\n",
        "\n",
        "        # Adjust the feature values in the swapped layers\n",
        "        if isinstance(network1_copy.layers[i], nn.Linear):\n",
        "            network1_copy.layers[i].in_features, network2_copy.layers[i].in_features = network2_copy.layers[i].in_features, network1_copy.layers[i].in_features\n",
        "            network1_copy.layers[i].out_features, network2_copy.layers[i].out_features = network2_copy.layers[i].out_features, network1_copy.layers[i].out_features\n",
        "\n",
        "        elif isinstance(network1_copy.layers[i], (nn.BatchNorm1d, nn.LayerNorm)):\n",
        "            # Find the index of the last linear layer before the swap position in network1_copy\n",
        "            last_linear_index_1 = -1\n",
        "            for j in range(i - 1, -1, -1):\n",
        "                if isinstance(network1_copy.layers[j], nn.Linear):\n",
        "                    last_linear_index_1 = j\n",
        "                    break\n",
        "\n",
        "            # Find the index of the last linear layer before the swap position in network2_copy\n",
        "            last_linear_index_2 = -1\n",
        "            for j in range(i - 1, -1, -1):\n",
        "                if isinstance(network2_copy.layers[j], nn.Linear):\n",
        "                    last_linear_index_2 = j\n",
        "                    break\n",
        "\n",
        "            if last_linear_index_1 != -1 and last_linear_index_2 != -1:\n",
        "                # Adjust the feature values in the batch normalization or layer normalization layers\n",
        "                last_linear_output_1 = network1_copy.layers[last_linear_index_1].out_features\n",
        "                last_linear_output_2 = network2_copy.layers[last_linear_index_2].out_features\n",
        "\n",
        "                network1_copy.layers[i].num_features = last_linear_output_1\n",
        "                network2_copy.layers[i].num_features = last_linear_output_2\n",
        "\n",
        "                network1_copy.layers[i].normalized_shape = (16, last_linear_output_1)\n",
        "                network2_copy.layers[i].normalized_shape = (16, last_linear_output_2)\n",
        "\n",
        "\n",
        "    return network1_copy, network2_copy\n"
      ],
      "metadata": {
        "id": "AXr5jNB7h6wB"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network1_copy, network2_copy = crossover_networks(model1, model2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IeUkC0riSKv",
        "outputId": "1b821eed-6d7e-4987-f547-844a867e880e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cutoff points for the crossover are [2, 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see below, even after the crossover the number of input features is coherent with the number of output features of the previous layer."
      ],
      "metadata": {
        "id": "tt3EsKPpGHgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(network1_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYvD4-0OEfau",
        "outputId": "8f505d74-9978-48b5-a435-b0bb5cb7241c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): AlphaDropout(p=0.7, inplace=False)\n",
            "    (2): AlphaDropout(p=0.1, inplace=False)\n",
            "    (3): BatchNorm1d(512, eps=1e-05, momentum=0.99, affine=True, track_running_stats=True)\n",
            "    (4): AlphaDropout(p=0.1, inplace=False)\n",
            "    (5): ReLU()\n",
            "    (6): CELU(alpha=1.0)\n",
            "    (7): BatchNorm1d(512, eps=0.001, momentum=0.9, affine=True, track_running_stats=True)\n",
            "    (8): BatchNorm1d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
            "    (9): Dropout(p=0.5, inplace=False)\n",
            "    (10): AlphaDropout(p=0.7, inplace=False)\n",
            "    (11): Dropout(p=0.7, inplace=False)\n",
            "    (12-13): 2 x LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
            "    (14): BatchNorm1d(512, eps=0.0001, momentum=0.9, affine=True, track_running_stats=True)\n",
            "    (15): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): AlphaDropout(p=0.7, inplace=False)\n",
            "    (17): GELU(approximate='none')\n",
            "    (18): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): AlphaDropout(p=0.1, inplace=False)\n",
            "    (20): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (21): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (22): Linear(in_features=256, out_features=32, bias=True)\n",
            "    (23): Dropout(p=0.1, inplace=False)\n",
            "    (24): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (25): Linear(in_features=32, out_features=10, bias=True)\n",
            "  )\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(network2_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2-wvEM8EoP5",
        "outputId": "0b5ec44c-46ef-456c-abfe-04580c8d5892"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ELU(alpha=1.0)\n",
            "    (2): Linear(in_features=512, out_features=64, bias=True)\n",
            "    (3): LayerNorm((16, 64), eps=0.001, elementwise_affine=True)\n",
            "    (4): Dropout(p=0.1, inplace=False)\n",
            "    (5): Dropout(p=0.7, inplace=False)\n",
            "    (6): AlphaDropout(p=0.1, inplace=False)\n",
            "    (7): BatchNorm1d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): Dropout(p=0.7, inplace=False)\n",
            "    (10): AlphaDropout(p=0.7, inplace=False)\n",
            "    (11): BatchNorm1d(64, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "    (12): Linear(in_features=64, out_features=512, bias=True)\n",
            "    (13): AlphaDropout(p=0.7, inplace=False)\n",
            "    (14): Dropout(p=0.1, inplace=False)\n",
            "    (15): AlphaDropout(p=0.1, inplace=False)\n",
            "    (16): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (17): LayerNorm((16, 512), eps=1e-05, elementwise_affine=True)\n",
            "    (18): Dropout(p=0.5, inplace=False)\n",
            "    (19): Dropout(p=0.1, inplace=False)\n",
            "    (20): Linear(in_features=512, out_features=128, bias=True)\n",
            "    (21): Dropout(p=0.7, inplace=False)\n",
            "    (22): ELU(alpha=1.0)\n",
            "    (23): BatchNorm1d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (24): AlphaDropout(p=0.5, inplace=False)\n",
            "    (25): CELU(alpha=1.0)\n",
            "    (26): LayerNorm((16, 128), eps=0.0001, elementwise_affine=True)\n",
            "    (27): ELU(alpha=1.0)\n",
            "    (28): BatchNorm1d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "    (29): LayerNorm((16, 128), eps=0.001, elementwise_affine=True)\n",
            "    (30): Dropout(p=0.5, inplace=False)\n",
            "    (31): Linear(in_features=128, out_features=256, bias=True)\n",
            "    (32): Dropout(p=0.7, inplace=False)\n",
            "    (33): Dropout(p=0.1, inplace=False)\n",
            "    (34): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(network1_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW9JhwgPEs_e",
        "outputId": "25c4e2f4-d28e-41c0-8832-307d42f578ad"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 2.3036  Training Accuracy: 0.1091\n",
            "Validation Loss: 2.2972  Validation Accuracy: 0.1526\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 2.3045  Training Accuracy: 0.1077\n",
            "Validation Loss: 2.3011  Validation Accuracy: 0.1181\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 2.3037  Training Accuracy: 0.1081\n",
            "Validation Loss: 2.2944  Validation Accuracy: 0.1175\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 2.3040  Training Accuracy: 0.1085\n",
            "Validation Loss: 2.2953  Validation Accuracy: 0.1569\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 2.3033  Training Accuracy: 0.1102\n",
            "Validation Loss: 2.3101  Validation Accuracy: 0.1162\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 2.3041  Training Accuracy: 0.1087\n",
            "Validation Loss: 2.3056  Validation Accuracy: 0.1201\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 2.3040  Training Accuracy: 0.1096\n",
            "Validation Loss: 2.3036  Validation Accuracy: 0.1030\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 2.3030  Training Accuracy: 0.1098\n",
            "Validation Loss: 2.3077  Validation Accuracy: 0.1191\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 2.3039  Training Accuracy: 0.1087\n",
            "Validation Loss: 2.3240  Validation Accuracy: 0.0852\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 2.3041  Training Accuracy: 0.1090\n",
            "Validation Loss: 2.3286  Validation Accuracy: 0.0744\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(network2_copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44Xp-v5mEvu-",
        "outputId": "7523476c-74c1-472d-ab03-5902619b5ab4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 3.2231  Training Accuracy: 0.1002\n",
            "Validation Loss: 2.6348  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 3.2145  Training Accuracy: 0.1023\n",
            "Validation Loss: 2.6352  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 3.2208  Training Accuracy: 0.1019\n",
            "Validation Loss: 2.6348  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 3.2312  Training Accuracy: 0.1013\n",
            "Validation Loss: 2.6348  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 3.2269  Training Accuracy: 0.0993\n",
            "Validation Loss: 2.6355  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 3.2416  Training Accuracy: 0.0985\n",
            "Validation Loss: 2.6370  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 3.2339  Training Accuracy: 0.0988\n",
            "Validation Loss: 2.6371  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 3.2182  Training Accuracy: 0.1018\n",
            "Validation Loss: 2.6364  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 3.2137  Training Accuracy: 0.1034\n",
            "Validation Loss: 2.6343  Validation Accuracy: 0.1033\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 3.2195  Training Accuracy: 0.1020\n",
            "Validation Loss: 2.6351  Validation Accuracy: 0.1033\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 3 with add layer mutation"
      ],
      "metadata": {
        "id": "qpr4cchXf0Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_layer_mutation(network):\n",
        "    # Clone the original network\n",
        "    new_network = copy.deepcopy(network)\n",
        "\n",
        "    # Generate 1 layer at random (the first and third layers will be the linear default ones)\n",
        "    random_network = generate_random_network(input_size=0, output_size=0, min_layers=1, max_layers=3)\n",
        "\n",
        "    # Get the right layer string from the randomly generated network\n",
        "    new_layer_str = random_network[1]  # Assuming there is only one layer in the random network\n",
        "\n",
        "    # Parse the layer string and convert it into a layer object\n",
        "    new_layer = new_network.parse_layer_string(new_layer_str)\n",
        "\n",
        "    # Randomly choose a position for the new layer\n",
        "    insert_index = random.randint(1, len(new_network.layers) - 1)  # Exclude the first and last layers\n",
        "    print(\"The new random layer will be inserted at position \", insert_index)\n",
        "\n",
        "    # Check if the new layer is Linear, BatchNorm1d, or LayerNorm\n",
        "    if isinstance(new_layer, (nn.Linear, nn.BatchNorm1d, nn.LayerNorm)):\n",
        "        # Find the index of the last linear layer before the insert position\n",
        "        last_linear_index = -1\n",
        "        for i in range(insert_index - 1, -1, -1):\n",
        "            if isinstance(new_network.layers[i], nn.Linear):\n",
        "                last_linear_index = i\n",
        "                break\n",
        "        # Get the output size of the last linear layer\n",
        "        last_linear_output = new_network.layers[last_linear_index].out_features\n",
        "\n",
        "        # Adjust the number of features in the new layer\n",
        "        if isinstance(new_layer, nn.Linear):\n",
        "            new_layer.in_features = last_linear_output\n",
        "            new_layer.out_features = new_layer.in_features #it will output the same number of features to not disrupt the sequence\n",
        "        elif isinstance(new_layer, nn.BatchNorm1d):\n",
        "            new_layer.num_features = last_linear_output\n",
        "        elif isinstance(new_layer, nn.LayerNorm):\n",
        "            new_layer.normalized_shape = (16, last_linear_output)\n",
        "\n",
        "    # Insert the new layer into the genotype at the chosen position\n",
        "    new_network.layers.insert(insert_index, new_layer)\n",
        "\n",
        "    return new_network"
      ],
      "metadata": {
        "id": "5NCWaJB0g4WA"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_network = add_layer_mutation(model3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FsAEnEMldGl",
        "outputId": "3fbc7bab-a30b-4719-d512-c0ac4494260a"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The new random layer will be inserted at position  30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAukU_4kHoT0",
        "outputId": "ba7dde98-f18a-4681-f630-3c4e1e97b4d9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): AlphaDropout(p=0.1, inplace=False)\n",
            "    (2): BatchNorm1d(512, eps=0.001, momentum=0.9, affine=True, track_running_stats=True)\n",
            "    (3): BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): Sigmoid()\n",
            "    (5): BatchNorm1d(512, eps=0.001, momentum=0.99, affine=True, track_running_stats=True)\n",
            "    (6): SiLU()\n",
            "    (7): LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
            "    (8): SELU()\n",
            "    (9): AlphaDropout(p=0.7, inplace=False)\n",
            "    (10): LayerNorm((16, 512), eps=0.001, elementwise_affine=True)\n",
            "    (11): AlphaDropout(p=0.1, inplace=False)\n",
            "    (12): LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
            "    (13): CELU(alpha=1.0)\n",
            "    (14): Linear(in_features=512, out_features=64, bias=True)\n",
            "    (15): Dropout(p=0.7, inplace=False)\n",
            "    (16): AlphaDropout(p=0.5, inplace=False)\n",
            "    (17): AlphaDropout(p=0.7, inplace=False)\n",
            "    (18): Sigmoid()\n",
            "    (19): AlphaDropout(p=0.7, inplace=False)\n",
            "    (20): LayerNorm((16, 64), eps=0.0001, elementwise_affine=True)\n",
            "    (21): Dropout(p=0.5, inplace=False)\n",
            "    (22): Linear(in_features=64, out_features=256, bias=True)\n",
            "    (23): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (24): BatchNorm1d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True)\n",
            "    (25): ELU(alpha=1.0)\n",
            "    (26): BatchNorm1d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): AlphaDropout(p=0.7, inplace=False)\n",
            "    (28): LayerNorm((16, 128), eps=1e-05, elementwise_affine=True)\n",
            "    (29): SiLU()\n",
            "    (30): Dropout(p=0.1, inplace=False)\n",
            "    (31): SELU()\n",
            "    (32): LayerNorm((16, 128), eps=0.001, elementwise_affine=True)\n",
            "    (33): BatchNorm1d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (34): Linear(in_features=128, out_features=10, bias=True)\n",
            "  )\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(new_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1GkUzceH1kE",
        "outputId": "dd5f3b73-b8c4-4485-cc31-fd39e4ac03dd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 2.3025  Training Accuracy: 0.1094\n",
            "Validation Loss: 2.2953  Validation Accuracy: 0.1156\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 2.3026  Training Accuracy: 0.1109\n",
            "Validation Loss: 2.2950  Validation Accuracy: 0.1155\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 2.3026  Training Accuracy: 0.1107\n",
            "Validation Loss: 2.2958  Validation Accuracy: 0.1179\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 2.3026  Training Accuracy: 0.1101\n",
            "Validation Loss: 2.2961  Validation Accuracy: 0.1117\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 2.3024  Training Accuracy: 0.1110\n",
            "Validation Loss: 2.2937  Validation Accuracy: 0.1276\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 2.3025  Training Accuracy: 0.1110\n",
            "Validation Loss: 2.2956  Validation Accuracy: 0.1192\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 2.3025  Training Accuracy: 0.1114\n",
            "Validation Loss: 2.2981  Validation Accuracy: 0.1028\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 2.3025  Training Accuracy: 0.1092\n",
            "Validation Loss: 2.2968  Validation Accuracy: 0.1186\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 2.3025  Training Accuracy: 0.1101\n",
            "Validation Loss: 2.2931  Validation Accuracy: 0.1208\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 2.3025  Training Accuracy: 0.1109\n",
            "Validation Loss: 2.2914  Validation Accuracy: 0.1156\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 4 with remove layer mutation"
      ],
      "metadata": {
        "id": "TPfnD6G0f0ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_layer_mutation(network):\n",
        "    # Clone the original network\n",
        "    new_network = copy.deepcopy(network)\n",
        "\n",
        "    # Check the number of layers in the network genotype\n",
        "    num_layers = len(new_network.layers)\n",
        "\n",
        "    # Randomly choose a layer to remove (excluding the first and last layers)\n",
        "    remove_index = random.randint(1, num_layers - 2)\n",
        "    print(\"The position of the layer that will be removed is \", remove_index)\n",
        "    \n",
        "    # Remove the layer from the genotype\n",
        "    removed_layer = new_network.layers.pop(remove_index)\n",
        "\n",
        "    # Check if the removed layer is a Linear layer\n",
        "    if isinstance(removed_layer, nn.Linear):\n",
        "        next_linear_index = -1\n",
        "        for i in range(remove_index, num_layers):\n",
        "            if isinstance(new_network.layers[i], nn.Linear):\n",
        "                next_linear_index = i\n",
        "                break\n",
        "\n",
        "        if next_linear_index != -1:\n",
        "            next_linear_layer = new_network.layers[next_linear_index]\n",
        "            next_linear_layer.in_features = removed_layer.in_features\n",
        "\n",
        "            for i in range(remove_index + 1, next_linear_index):\n",
        "                if isinstance(new_network.layers[i], nn.BatchNorm1d):\n",
        "                    new_network.layers[i].num_features = removed_layer.in_features\n",
        "\n",
        "                elif isinstance(new_network.layers[i], nn.LayerNorm):\n",
        "                    new_network.layers[i].normalized_shape = (16, removed_layer.in_features)\n",
        "\n",
        "    return new_network"
      ],
      "metadata": {
        "id": "1DaoCXnQnnTi"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_network = remove_layer_mutation(model4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9smDPAoZnxaH",
        "outputId": "df98ebec-29ec-4655-8cfb-84681f1dd1d2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The position of the layer that will be removed is  3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krhCC8ITJvGl",
        "outputId": "6a437f81-4564-476a-ad58-4b2150d932f1"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ELU(alpha=1.0)\n",
            "    (2): SiLU()\n",
            "    (3): LayerNorm((16, 512), eps=0.001, elementwise_affine=True)\n",
            "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (5): LayerNorm((16, 512), eps=0.0001, elementwise_affine=True)\n",
            "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(new_network)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3j8icgTnJouJ",
        "outputId": "a5676e2c-3797-4678-8c0d-afbc584e34d7"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 0.0707  Training Accuracy: 0.9776\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 0.0720  Training Accuracy: 0.9779\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 0.0702  Training Accuracy: 0.9780\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 0.0715  Training Accuracy: 0.9775\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 0.0714  Training Accuracy: 0.9779\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 0.0713  Training Accuracy: 0.9778\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 0.0721  Training Accuracy: 0.9774\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 0.0716  Training Accuracy: 0.9779\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 0.0714  Training Accuracy: 0.9779\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 0.0720  Training Accuracy: 0.9777\n",
            "Validation Loss: 0.1593  Validation Accuracy: 0.9614\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network 5 with change optimizer mutation"
      ],
      "metadata": {
        "id": "5ozmoeS8f02S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_optimizer_mutation(model, optimizer_str):\n",
        "    # Randomly select a new optimizer\n",
        "    new_optimizer_str = random.choice(list(optimizer_params.keys()))\n",
        "\n",
        "    if new_optimizer_str == optimizer_str:\n",
        "        # The optimizer did not change, so we will select a random parameter to change its value\n",
        "        params = optimizer_params[optimizer_str].copy()  # Make a copy of the parameters\n",
        "\n",
        "        # Randomly select a parameter to change\n",
        "        param_to_change = random.choice(list(params.keys()))\n",
        "\n",
        "        # Randomly select a new value for the parameter\n",
        "        new_value = random.choice(optimizer_params[optimizer_str][param_to_change])\n",
        "\n",
        "        # Update the parameter with the new value\n",
        "        params[param_to_change] = new_value\n",
        "    else:\n",
        "        # The optimizer changed, so we need to select new parameters for the new optimizer\n",
        "        new_optimizer_params = optimizer_params[new_optimizer_str]\n",
        "        params = {}\n",
        "        for param, values in new_optimizer_params.items():\n",
        "            params[param] = random.choice(values)\n",
        "\n",
        "    # Print the randomly generated optimizer and its parameters\n",
        "    print(\"Optimizer:\", new_optimizer_str)\n",
        "    print(\"Parameters:\", params)\n",
        "\n",
        "    # Rebuild the optimizer with the new optimizer string and parameters\n",
        "    optimizer = build_optimizer(new_optimizer_str, params, model)\n",
        "    return optimizer\n"
      ],
      "metadata": {
        "id": "iR3uc7oRoroj"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = change_optimizer_mutation(model5, optimizer_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR6pjSIGosJ2",
        "outputId": "bd0cbc1d-c801-4363-f80d-2386dfaf12ef"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimizer: Adam\n",
            "Parameters: {'lr': 0.001, 'betas': (0.85, 0.95)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kdBBQoZKzWt",
        "outputId": "fbd288f7-80a7-4694-9b0b-839f8ab43810"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "Training Loss: 2.2337  Training Accuracy: 0.1708\n",
            "Validation Loss: 1.3555  Validation Accuracy: 0.5721\n",
            "------------------------\n",
            "Epoch 2/10\n",
            "Training Loss: 2.2196  Training Accuracy: 0.1762\n",
            "Validation Loss: 1.4887  Validation Accuracy: 0.5179\n",
            "------------------------\n",
            "Epoch 3/10\n",
            "Training Loss: 2.2138  Training Accuracy: 0.1798\n",
            "Validation Loss: 1.4069  Validation Accuracy: 0.5359\n",
            "------------------------\n",
            "Epoch 4/10\n",
            "Training Loss: 2.2142  Training Accuracy: 0.1770\n",
            "Validation Loss: 1.3402  Validation Accuracy: 0.6093\n",
            "------------------------\n",
            "Epoch 5/10\n",
            "Training Loss: 2.2225  Training Accuracy: 0.1732\n",
            "Validation Loss: 1.2619  Validation Accuracy: 0.5819\n",
            "------------------------\n",
            "Epoch 6/10\n",
            "Training Loss: 2.2271  Training Accuracy: 0.1723\n",
            "Validation Loss: 1.4103  Validation Accuracy: 0.5307\n",
            "------------------------\n",
            "Epoch 7/10\n",
            "Training Loss: 2.2364  Training Accuracy: 0.1659\n",
            "Validation Loss: 1.4790  Validation Accuracy: 0.4943\n",
            "------------------------\n",
            "Epoch 8/10\n",
            "Training Loss: 2.2501  Training Accuracy: 0.1572\n",
            "Validation Loss: 1.4973  Validation Accuracy: 0.4588\n",
            "------------------------\n",
            "Epoch 9/10\n",
            "Training Loss: 2.2558  Training Accuracy: 0.1527\n",
            "Validation Loss: 1.4111  Validation Accuracy: 0.4830\n",
            "------------------------\n",
            "Epoch 10/10\n",
            "Training Loss: 2.2606  Training Accuracy: 0.1527\n",
            "Validation Loss: 1.6035  Validation Accuracy: 0.4223\n",
            "------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The end. ðŸ”š"
      ],
      "metadata": {
        "id": "iLW8y1vpML9t"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}